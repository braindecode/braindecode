{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read and Decode BBCI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial shows how to read and decode BBCI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First set the filename and the sensors you want to load. If you set\n",
    "\n",
    "```python\n",
    "load_sensor_names=None\n",
    "```\n",
    "\n",
    "or just remove the parameter from the function call, all sensors will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=3451320\n",
      "    Range : 0 ... 3451319 =      0.000 ...  6902.638 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "train_filename = '/home/schirrmr/data/BBCI-without-last-runs/BhNoMoSc1S001R01_ds10_1-12.BBCI.mat'\n",
    "cnt = BBCIDataset(train_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing on continous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First remove the stimulus channel, than apply any preprocessing you like. There are some very few directions available from Braindecode, such as resample_cnt. But you can apply any function on the chan x time matrix of the mne raw object (`cnt` in the code) by calling `mne_apply` with two arguments:\n",
    "\n",
    "1. Your function (2d-array-> 2darray), that transforms the channel x timesteps data array\n",
    "2. the Raw data object from mne itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 21:23:27,162 WARNING : This is not causal, uses future data....\n",
      "2017-07-05 21:23:27,165 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=1725660\n",
      "    Range : 0 ... 1725659 =      0.000 ...  6902.636 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "# mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "# have to transpose data back and forth, since\n",
    "# exponential_running_standardize expects time x chans order\n",
    "# while mne object has chans x time order\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Transform to epoched dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode supplies the `create_signal_target_from_raw_mne` function, which will transform the mne raw object into a `SignalAndTarget` object for use in Braindecode.\n",
    "`name_to_code` should be an `OrderedDict` that maps class names to either one or a list of marker codes for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 21:23:31,997 INFO : Trial per class:\n",
      "Counter({'Feet': 225, 'Rest': 224, 'Right': 224, 'Left': 224})\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "from collections import OrderedDict\n",
    "# can also give lists of marker codes in case a class has multiple marker codes...\n",
    "name_to_code = OrderedDict([('Right', 1), ('Left', 2), ('Rest', 3), ('Feet', 4)])\n",
    "segment_ival_ms = [-500,4000]\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=617090\n",
      "    Range : 0 ... 617089 =      0.000 ...  1234.178 secs\n",
      "Ready.\n",
      "2017-07-05 21:23:35,700 WARNING : This is not causal, uses future data....\n",
      "2017-07-05 21:23:35,702 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=308545\n",
      "    Range : 0 ... 308544 =      0.000 ...  1234.176 secs\n",
      "Ready.\n",
      "2017-07-05 21:23:36,968 INFO : Trial per class:\n",
      "Counter({'Rest': 40, 'Feet': 40, 'Right': 40, 'Left': 40})\n"
     ]
    }
   ],
   "source": [
    "test_filename = '/home/schirrmr/data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10_1-2BBCI.mat'\n",
    "cnt = BBCIDataset(test_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)\n",
    "test_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "In case of start and stop markers, provide a `name_to_stop_codes` dictionary (same as for the start codes in this example) as a final argument to `create_signal_target_from_raw_mne`. See [Read and Decode BBCI Data with Start-Stop-Markers Tutorial](BBCI_Data_Start_Stop.html)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 21:23:58,708 INFO : Run until first stop...\n",
      "2017-07-05 21:23:59,764 INFO : Epoch 0\n",
      "2017-07-05 21:23:59,767 INFO : train_loss                7.89184\n",
      "2017-07-05 21:23:59,769 INFO : valid_loss                7.72731\n",
      "2017-07-05 21:23:59,770 INFO : test_loss                 7.75617\n",
      "2017-07-05 21:23:59,772 INFO : train_sample_misclass     0.75013\n",
      "2017-07-05 21:23:59,773 INFO : valid_sample_misclass     0.74856\n",
      "2017-07-05 21:23:59,775 INFO : test_sample_misclass      0.75115\n",
      "2017-07-05 21:23:59,777 INFO : train_misclass            0.75070\n",
      "2017-07-05 21:23:59,778 INFO : valid_misclass            0.74860\n",
      "2017-07-05 21:23:59,780 INFO : test_misclass             0.75000\n",
      "2017-07-05 21:23:59,781 INFO : runtime                   0.00000\n",
      "2017-07-05 21:23:59,783 INFO : \n",
      "2017-07-05 21:23:59,785 INFO : New best valid_misclass: 0.748603\n",
      "2017-07-05 21:23:59,787 INFO : \n",
      "2017-07-05 21:24:03,856 INFO : Epoch 1\n",
      "2017-07-05 21:24:03,885 INFO : train_loss                0.79533\n",
      "2017-07-05 21:24:03,888 INFO : valid_loss                0.79277\n",
      "2017-07-05 21:24:03,890 INFO : test_loss                 0.83720\n",
      "2017-07-05 21:24:03,892 INFO : train_sample_misclass     0.36973\n",
      "2017-07-05 21:24:03,895 INFO : valid_sample_misclass     0.37372\n",
      "2017-07-05 21:24:03,897 INFO : test_sample_misclass      0.43015\n",
      "2017-07-05 21:24:03,899 INFO : train_misclass            0.30223\n",
      "2017-07-05 21:24:03,901 INFO : valid_misclass            0.26257\n",
      "2017-07-05 21:24:03,904 INFO : test_misclass             0.33750\n",
      "2017-07-05 21:24:03,906 INFO : runtime                   2.48741\n",
      "2017-07-05 21:24:03,908 INFO : \n",
      "2017-07-05 21:24:03,912 INFO : New best valid_misclass: 0.262570\n",
      "2017-07-05 21:24:03,917 INFO : \n",
      "2017-07-05 21:24:06,468 INFO : Epoch 2\n",
      "2017-07-05 21:24:06,470 INFO : train_loss                0.68135\n",
      "2017-07-05 21:24:06,472 INFO : valid_loss                0.65928\n",
      "2017-07-05 21:24:06,473 INFO : test_loss                 0.74289\n",
      "2017-07-05 21:24:06,475 INFO : train_sample_misclass     0.29307\n",
      "2017-07-05 21:24:06,476 INFO : valid_sample_misclass     0.30288\n",
      "2017-07-05 21:24:06,478 INFO : test_sample_misclass      0.37372\n",
      "2017-07-05 21:24:06,479 INFO : train_misclass            0.22423\n",
      "2017-07-05 21:24:06,481 INFO : valid_misclass            0.20670\n",
      "2017-07-05 21:24:06,482 INFO : test_misclass             0.29375\n",
      "2017-07-05 21:24:06,484 INFO : runtime                   4.28294\n",
      "2017-07-05 21:24:06,485 INFO : \n",
      "2017-07-05 21:24:06,488 INFO : New best valid_misclass: 0.206704\n",
      "2017-07-05 21:24:06,489 INFO : \n",
      "2017-07-05 21:24:09,260 INFO : Epoch 3\n",
      "2017-07-05 21:24:09,261 INFO : train_loss                0.65509\n",
      "2017-07-05 21:24:09,262 INFO : valid_loss                0.68479\n",
      "2017-07-05 21:24:09,263 INFO : test_loss                 0.81792\n",
      "2017-07-05 21:24:09,263 INFO : train_sample_misclass     0.27867\n",
      "2017-07-05 21:24:09,264 INFO : valid_sample_misclass     0.32166\n",
      "2017-07-05 21:24:09,265 INFO : test_sample_misclass      0.43583\n",
      "2017-07-05 21:24:09,265 INFO : train_misclass            0.20334\n",
      "2017-07-05 21:24:09,266 INFO : valid_misclass            0.26257\n",
      "2017-07-05 21:24:09,280 INFO : test_misclass             0.35625\n",
      "2017-07-05 21:24:09,281 INFO : runtime                   2.01804\n",
      "2017-07-05 21:24:09,282 INFO : \n",
      "2017-07-05 21:24:12,720 INFO : Epoch 4\n",
      "2017-07-05 21:24:12,723 INFO : train_loss                0.63604\n",
      "2017-07-05 21:24:12,724 INFO : valid_loss                0.63574\n",
      "2017-07-05 21:24:12,726 INFO : test_loss                 0.78911\n",
      "2017-07-05 21:24:12,727 INFO : train_sample_misclass     0.28602\n",
      "2017-07-05 21:24:12,729 INFO : valid_sample_misclass     0.29897\n",
      "2017-07-05 21:24:12,730 INFO : test_sample_misclass      0.37654\n",
      "2017-07-05 21:24:12,732 INFO : train_misclass            0.23398\n",
      "2017-07-05 21:24:12,734 INFO : valid_misclass            0.25140\n",
      "2017-07-05 21:24:12,735 INFO : test_misclass             0.33750\n",
      "2017-07-05 21:24:12,737 INFO : runtime                   3.27233\n",
      "2017-07-05 21:24:12,739 INFO : \n",
      "2017-07-05 21:24:16,056 INFO : Epoch 5\n",
      "2017-07-05 21:24:16,070 INFO : train_loss                0.70047\n",
      "2017-07-05 21:24:16,072 INFO : valid_loss                0.70172\n",
      "2017-07-05 21:24:16,074 INFO : test_loss                 0.79520\n",
      "2017-07-05 21:24:16,076 INFO : train_sample_misclass     0.29513\n",
      "2017-07-05 21:24:16,078 INFO : valid_sample_misclass     0.32462\n",
      "2017-07-05 21:24:16,080 INFO : test_sample_misclass      0.37390\n",
      "2017-07-05 21:24:16,082 INFO : train_misclass            0.24234\n",
      "2017-07-05 21:24:16,084 INFO : valid_misclass            0.29609\n",
      "2017-07-05 21:24:16,086 INFO : test_misclass             0.33125\n",
      "2017-07-05 21:24:16,088 INFO : runtime                   3.99029\n",
      "2017-07-05 21:24:16,090 INFO : \n",
      "2017-07-05 21:24:18,165 INFO : Epoch 6\n",
      "2017-07-05 21:24:18,168 INFO : train_loss                0.59056\n",
      "2017-07-05 21:24:18,169 INFO : valid_loss                0.61404\n",
      "2017-07-05 21:24:18,171 INFO : test_loss                 0.70548\n",
      "2017-07-05 21:24:18,172 INFO : train_sample_misclass     0.25147\n",
      "2017-07-05 21:24:18,174 INFO : valid_sample_misclass     0.26721\n",
      "2017-07-05 21:24:18,175 INFO : test_sample_misclass      0.33013\n",
      "2017-07-05 21:24:18,177 INFO : train_misclass            0.19359\n",
      "2017-07-05 21:24:18,178 INFO : valid_misclass            0.18436\n",
      "2017-07-05 21:24:18,180 INFO : test_misclass             0.28750\n",
      "2017-07-05 21:24:18,181 INFO : runtime                   2.54505\n",
      "2017-07-05 21:24:18,183 INFO : \n",
      "2017-07-05 21:24:18,185 INFO : New best valid_misclass: 0.184358\n",
      "2017-07-05 21:24:18,187 INFO : \n",
      "2017-07-05 21:24:20,338 INFO : Epoch 7\n",
      "2017-07-05 21:24:20,347 INFO : train_loss                0.58197\n",
      "2017-07-05 21:24:20,349 INFO : valid_loss                0.59347\n",
      "2017-07-05 21:24:20,351 INFO : test_loss                 0.69402\n",
      "2017-07-05 21:24:20,353 INFO : train_sample_misclass     0.23879\n",
      "2017-07-05 21:24:20,354 INFO : valid_sample_misclass     0.27989\n",
      "2017-07-05 21:24:20,356 INFO : test_sample_misclass      0.34760\n",
      "2017-07-05 21:24:20,358 INFO : train_misclass            0.16852\n",
      "2017-07-05 21:24:20,360 INFO : valid_misclass            0.21788\n",
      "2017-07-05 21:24:20,361 INFO : test_misclass             0.28750\n",
      "2017-07-05 21:24:20,363 INFO : runtime                   1.74632\n",
      "2017-07-05 21:24:20,365 INFO : \n",
      "2017-07-05 21:24:22,679 INFO : Epoch 8\n",
      "2017-07-05 21:24:22,682 INFO : train_loss                0.53383\n",
      "2017-07-05 21:24:22,683 INFO : valid_loss                0.59637\n",
      "2017-07-05 21:24:22,684 INFO : test_loss                 0.73685\n",
      "2017-07-05 21:24:22,685 INFO : train_sample_misclass     0.23251\n",
      "2017-07-05 21:24:22,686 INFO : valid_sample_misclass     0.27038\n",
      "2017-07-05 21:24:22,687 INFO : test_sample_misclass      0.36420\n",
      "2017-07-05 21:24:22,688 INFO : train_misclass            0.15460\n",
      "2017-07-05 21:24:22,689 INFO : valid_misclass            0.17877\n",
      "2017-07-05 21:24:22,690 INFO : test_misclass             0.22500\n",
      "2017-07-05 21:24:22,691 INFO : runtime                   2.54092\n",
      "2017-07-05 21:24:22,692 INFO : \n",
      "2017-07-05 21:24:22,694 INFO : New best valid_misclass: 0.178771\n",
      "2017-07-05 21:24:22,696 INFO : \n",
      "2017-07-05 21:24:25,205 INFO : Epoch 9\n",
      "2017-07-05 21:24:25,207 INFO : train_loss                0.54582\n",
      "2017-07-05 21:24:25,209 INFO : valid_loss                0.60366\n",
      "2017-07-05 21:24:25,210 INFO : test_loss                 0.70768\n",
      "2017-07-05 21:24:25,212 INFO : train_sample_misclass     0.22866\n",
      "2017-07-05 21:24:25,213 INFO : valid_sample_misclass     0.27743\n",
      "2017-07-05 21:24:25,215 INFO : test_sample_misclass      0.34714\n",
      "2017-07-05 21:24:25,216 INFO : train_misclass            0.15181\n",
      "2017-07-05 21:24:25,218 INFO : valid_misclass            0.20112\n",
      "2017-07-05 21:24:25,219 INFO : test_misclass             0.22500\n",
      "2017-07-05 21:24:25,221 INFO : runtime                   2.47122\n",
      "2017-07-05 21:24:25,222 INFO : \n",
      "2017-07-05 21:24:27,747 INFO : Epoch 10\n",
      "2017-07-05 21:24:27,754 INFO : train_loss                0.51431\n",
      "2017-07-05 21:24:27,756 INFO : valid_loss                0.49798\n",
      "2017-07-05 21:24:27,757 INFO : test_loss                 0.61335\n",
      "2017-07-05 21:24:27,759 INFO : train_sample_misclass     0.19945\n",
      "2017-07-05 21:24:27,761 INFO : valid_sample_misclass     0.22385\n",
      "2017-07-05 21:24:27,762 INFO : test_sample_misclass      0.28923\n",
      "2017-07-05 21:24:27,764 INFO : train_misclass            0.14067\n",
      "2017-07-05 21:24:27,766 INFO : valid_misclass            0.13966\n",
      "2017-07-05 21:24:27,768 INFO : test_misclass             0.18125\n",
      "2017-07-05 21:24:27,769 INFO : runtime                   2.35646\n",
      "2017-07-05 21:24:27,771 INFO : \n",
      "2017-07-05 21:24:27,774 INFO : New best valid_misclass: 0.139665\n",
      "2017-07-05 21:24:27,777 INFO : \n",
      "2017-07-05 21:24:29,847 INFO : Epoch 11\n",
      "2017-07-05 21:24:29,849 INFO : train_loss                0.50179\n",
      "2017-07-05 21:24:29,851 INFO : valid_loss                0.56065\n",
      "2017-07-05 21:24:29,852 INFO : test_loss                 0.62696\n",
      "2017-07-05 21:24:29,854 INFO : train_sample_misclass     0.19962\n",
      "2017-07-05 21:24:29,855 INFO : valid_sample_misclass     0.26165\n",
      "2017-07-05 21:24:29,857 INFO : test_sample_misclass      0.30565\n",
      "2017-07-05 21:24:29,858 INFO : train_misclass            0.11978\n",
      "2017-07-05 21:24:29,860 INFO : valid_misclass            0.20670\n",
      "2017-07-05 21:24:29,861 INFO : test_misclass             0.21875\n",
      "2017-07-05 21:24:29,862 INFO : runtime                   2.70309\n",
      "2017-07-05 21:24:29,864 INFO : \n",
      "2017-07-05 21:24:31,859 INFO : Epoch 12\n",
      "2017-07-05 21:24:31,864 INFO : train_loss                0.49190\n",
      "2017-07-05 21:24:31,866 INFO : valid_loss                0.53543\n",
      "2017-07-05 21:24:31,867 INFO : test_loss                 0.64607\n",
      "2017-07-05 21:24:31,869 INFO : train_sample_misclass     0.20347\n",
      "2017-07-05 21:24:31,878 INFO : valid_sample_misclass     0.23275\n",
      "2017-07-05 21:24:31,880 INFO : test_sample_misclass      0.31466\n",
      "2017-07-05 21:24:31,882 INFO : train_misclass            0.13092\n",
      "2017-07-05 21:24:31,883 INFO : valid_misclass            0.17877\n",
      "2017-07-05 21:24:31,884 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:31,886 INFO : runtime                   1.53223\n",
      "2017-07-05 21:24:31,887 INFO : \n",
      "2017-07-05 21:24:33,512 INFO : Epoch 13\n",
      "2017-07-05 21:24:33,514 INFO : train_loss                0.51957\n",
      "2017-07-05 21:24:33,516 INFO : valid_loss                0.56247\n",
      "2017-07-05 21:24:33,517 INFO : test_loss                 0.73568\n",
      "2017-07-05 21:24:33,519 INFO : train_sample_misclass     0.21524\n",
      "2017-07-05 21:24:33,520 INFO : valid_sample_misclass     0.25516\n",
      "2017-07-05 21:24:33,522 INFO : test_sample_misclass      0.36145\n",
      "2017-07-05 21:24:33,523 INFO : train_misclass            0.14763\n",
      "2017-07-05 21:24:33,525 INFO : valid_misclass            0.15084\n",
      "2017-07-05 21:24:33,526 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:33,528 INFO : runtime                   2.25504\n",
      "2017-07-05 21:24:33,529 INFO : \n",
      "2017-07-05 21:24:36,285 INFO : Epoch 14\n",
      "2017-07-05 21:24:36,296 INFO : train_loss                0.47774\n",
      "2017-07-05 21:24:36,298 INFO : valid_loss                0.50176\n",
      "2017-07-05 21:24:36,300 INFO : test_loss                 0.60000\n",
      "2017-07-05 21:24:36,302 INFO : train_sample_misclass     0.18290\n",
      "2017-07-05 21:24:36,304 INFO : valid_sample_misclass     0.22609\n",
      "2017-07-05 21:24:36,305 INFO : test_sample_misclass      0.29088\n",
      "2017-07-05 21:24:36,307 INFO : train_misclass            0.11421\n",
      "2017-07-05 21:24:36,309 INFO : valid_misclass            0.12291\n",
      "2017-07-05 21:24:36,310 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:36,312 INFO : runtime                   2.30552\n",
      "2017-07-05 21:24:36,314 INFO : \n",
      "2017-07-05 21:24:36,317 INFO : New best valid_misclass: 0.122905\n",
      "2017-07-05 21:24:36,320 INFO : \n",
      "2017-07-05 21:24:38,599 INFO : Epoch 15\n",
      "2017-07-05 21:24:38,600 INFO : train_loss                0.49172\n",
      "2017-07-05 21:24:38,601 INFO : valid_loss                0.53307\n",
      "2017-07-05 21:24:38,602 INFO : test_loss                 0.63148\n",
      "2017-07-05 21:24:38,602 INFO : train_sample_misclass     0.19327\n",
      "2017-07-05 21:24:38,603 INFO : valid_sample_misclass     0.22987\n",
      "2017-07-05 21:24:38,604 INFO : test_sample_misclass      0.30918\n",
      "2017-07-05 21:24:38,604 INFO : train_misclass            0.14206\n",
      "2017-07-05 21:24:38,605 INFO : valid_misclass            0.16760\n",
      "2017-07-05 21:24:38,606 INFO : test_misclass             0.25625\n",
      "2017-07-05 21:24:38,606 INFO : runtime                   2.28078\n",
      "2017-07-05 21:24:38,607 INFO : \n",
      "2017-07-05 21:24:40,464 INFO : Epoch 16\n",
      "2017-07-05 21:24:40,466 INFO : train_loss                0.58365\n",
      "2017-07-05 21:24:40,468 INFO : valid_loss                0.57222\n",
      "2017-07-05 21:24:40,469 INFO : test_loss                 0.69279\n",
      "2017-07-05 21:24:40,470 INFO : train_sample_misclass     0.23995\n",
      "2017-07-05 21:24:40,472 INFO : valid_sample_misclass     0.25260\n",
      "2017-07-05 21:24:40,473 INFO : test_sample_misclass      0.34590\n",
      "2017-07-05 21:24:40,475 INFO : train_misclass            0.20752\n",
      "2017-07-05 21:24:40,476 INFO : valid_misclass            0.19553\n",
      "2017-07-05 21:24:40,478 INFO : test_misclass             0.29375\n",
      "2017-07-05 21:24:40,479 INFO : runtime                   2.18737\n",
      "2017-07-05 21:24:40,481 INFO : \n",
      "2017-07-05 21:24:42,503 INFO : Epoch 17\n",
      "2017-07-05 21:24:42,505 INFO : train_loss                0.56334\n",
      "2017-07-05 21:24:42,506 INFO : valid_loss                0.59551\n",
      "2017-07-05 21:24:42,507 INFO : test_loss                 0.66440\n",
      "2017-07-05 21:24:42,508 INFO : train_sample_misclass     0.22313\n",
      "2017-07-05 21:24:42,508 INFO : valid_sample_misclass     0.26574\n",
      "2017-07-05 21:24:42,509 INFO : test_sample_misclass      0.33439\n",
      "2017-07-05 21:24:42,510 INFO : train_misclass            0.17270\n",
      "2017-07-05 21:24:42,510 INFO : valid_misclass            0.19553\n",
      "2017-07-05 21:24:42,511 INFO : test_misclass             0.25000\n",
      "2017-07-05 21:24:42,512 INFO : runtime                   1.75812\n",
      "2017-07-05 21:24:42,513 INFO : \n",
      "2017-07-05 21:24:44,820 INFO : Epoch 18\n",
      "2017-07-05 21:24:44,837 INFO : train_loss                0.49272\n",
      "2017-07-05 21:24:44,838 INFO : valid_loss                0.54402\n",
      "2017-07-05 21:24:44,840 INFO : test_loss                 0.63941\n",
      "2017-07-05 21:24:44,841 INFO : train_sample_misclass     0.19630\n",
      "2017-07-05 21:24:44,843 INFO : valid_sample_misclass     0.25872\n",
      "2017-07-05 21:24:44,844 INFO : test_sample_misclass      0.32125\n",
      "2017-07-05 21:24:44,846 INFO : train_misclass            0.11281\n",
      "2017-07-05 21:24:44,847 INFO : valid_misclass            0.16760\n",
      "2017-07-05 21:24:44,849 INFO : test_misclass             0.23750\n",
      "2017-07-05 21:24:44,850 INFO : runtime                   2.06231\n",
      "2017-07-05 21:24:44,852 INFO : \n",
      "2017-07-05 21:24:46,944 INFO : Epoch 19\n",
      "2017-07-05 21:24:46,945 INFO : train_loss                0.46494\n",
      "2017-07-05 21:24:46,946 INFO : valid_loss                0.53740\n",
      "2017-07-05 21:24:46,947 INFO : test_loss                 0.65596\n",
      "2017-07-05 21:24:46,949 INFO : train_sample_misclass     0.19214\n",
      "2017-07-05 21:24:46,950 INFO : valid_sample_misclass     0.23241\n",
      "2017-07-05 21:24:46,952 INFO : test_sample_misclass      0.33758\n",
      "2017-07-05 21:24:46,953 INFO : train_misclass            0.12396\n",
      "2017-07-05 21:24:46,955 INFO : valid_misclass            0.14525\n",
      "2017-07-05 21:24:46,956 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:46,958 INFO : runtime                   2.52590\n",
      "2017-07-05 21:24:46,959 INFO : \n",
      "2017-07-05 21:24:49,511 INFO : Epoch 20\n",
      "2017-07-05 21:24:49,524 INFO : train_loss                0.45515\n",
      "2017-07-05 21:24:49,526 INFO : valid_loss                0.52908\n",
      "2017-07-05 21:24:49,527 INFO : test_loss                 0.60898\n",
      "2017-07-05 21:24:49,529 INFO : train_sample_misclass     0.17942\n",
      "2017-07-05 21:24:49,531 INFO : valid_sample_misclass     0.24017\n",
      "2017-07-05 21:24:49,533 INFO : test_sample_misclass      0.28970\n",
      "2017-07-05 21:24:49,534 INFO : train_misclass            0.10028\n",
      "2017-07-05 21:24:49,536 INFO : valid_misclass            0.15084\n",
      "2017-07-05 21:24:49,538 INFO : test_misclass             0.20000\n",
      "2017-07-05 21:24:49,540 INFO : runtime                   1.76174\n",
      "2017-07-05 21:24:49,541 INFO : \n",
      "2017-07-05 21:24:49,543 INFO : Setup for second stop...\n",
      "2017-07-05 21:24:49,547 INFO : Train loss to reach 0.47774\n",
      "2017-07-05 21:24:49,551 INFO : Run until second stop...\n",
      "2017-07-05 21:24:50,558 INFO : Epoch 15\n",
      "2017-07-05 21:24:50,559 INFO : train_loss                0.48254\n",
      "2017-07-05 21:24:50,560 INFO : valid_loss                0.50176\n",
      "2017-07-05 21:24:50,561 INFO : test_loss                 0.60000\n",
      "2017-07-05 21:24:50,561 INFO : train_sample_misclass     0.19152\n",
      "2017-07-05 21:24:50,562 INFO : valid_sample_misclass     0.22609\n",
      "2017-07-05 21:24:50,563 INFO : test_sample_misclass      0.29088\n",
      "2017-07-05 21:24:50,564 INFO : train_misclass            0.11594\n",
      "2017-07-05 21:24:50,564 INFO : valid_misclass            0.12291\n",
      "2017-07-05 21:24:50,565 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:50,566 INFO : runtime                   1.75865\n",
      "2017-07-05 21:24:50,567 INFO : \n",
      "2017-07-05 21:24:52,565 INFO : Epoch 16\n",
      "2017-07-05 21:24:52,566 INFO : train_loss                0.50978\n",
      "2017-07-05 21:24:52,567 INFO : valid_loss                0.51168\n",
      "2017-07-05 21:24:52,567 INFO : test_loss                 0.62886\n",
      "2017-07-05 21:24:52,568 INFO : train_sample_misclass     0.21273\n",
      "2017-07-05 21:24:52,569 INFO : valid_sample_misclass     0.23489\n",
      "2017-07-05 21:24:52,569 INFO : test_sample_misclass      0.30946\n",
      "2017-07-05 21:24:52,570 INFO : train_misclass            0.15608\n",
      "2017-07-05 21:24:52,570 INFO : valid_misclass            0.16760\n",
      "2017-07-05 21:24:52,571 INFO : test_misclass             0.23125\n",
      "2017-07-05 21:24:52,571 INFO : runtime                   2.24314\n",
      "2017-07-05 21:24:52,572 INFO : \n",
      "2017-07-05 21:24:54,575 INFO : Epoch 17\n",
      "2017-07-05 21:24:54,578 INFO : train_loss                0.47943\n",
      "2017-07-05 21:24:54,579 INFO : valid_loss                0.50067\n",
      "2017-07-05 21:24:54,581 INFO : test_loss                 0.64929\n",
      "2017-07-05 21:24:54,583 INFO : train_sample_misclass     0.21200\n",
      "2017-07-05 21:24:54,584 INFO : valid_sample_misclass     0.22710\n",
      "2017-07-05 21:24:54,585 INFO : test_sample_misclass      0.32878\n",
      "2017-07-05 21:24:54,587 INFO : train_misclass            0.14047\n",
      "2017-07-05 21:24:54,588 INFO : valid_misclass            0.16201\n",
      "2017-07-05 21:24:54,590 INFO : test_misclass             0.25000\n",
      "2017-07-05 21:24:54,592 INFO : runtime                   1.78975\n",
      "2017-07-05 21:24:54,594 INFO : \n",
      "2017-07-05 21:24:56,381 INFO : Epoch 18\n",
      "2017-07-05 21:24:56,382 INFO : train_loss                0.61305\n",
      "2017-07-05 21:24:56,383 INFO : valid_loss                0.62703\n",
      "2017-07-05 21:24:56,384 INFO : test_loss                 0.82444\n",
      "2017-07-05 21:24:56,384 INFO : train_sample_misclass     0.26830\n",
      "2017-07-05 21:24:56,385 INFO : valid_sample_misclass     0.26894\n",
      "2017-07-05 21:24:56,386 INFO : test_sample_misclass      0.37419\n",
      "2017-07-05 21:24:56,386 INFO : train_misclass            0.21405\n",
      "2017-07-05 21:24:56,387 INFO : valid_misclass            0.22905\n",
      "2017-07-05 21:24:56,388 INFO : test_misclass             0.34375\n",
      "2017-07-05 21:24:56,388 INFO : runtime                   1.92751\n",
      "2017-07-05 21:24:56,389 INFO : \n",
      "2017-07-05 21:24:58,335 INFO : Epoch 19\n",
      "2017-07-05 21:24:58,336 INFO : train_loss                0.44958\n",
      "2017-07-05 21:24:58,337 INFO : valid_loss                0.42829\n",
      "2017-07-05 21:24:58,338 INFO : test_loss                 0.56561\n",
      "2017-07-05 21:24:58,339 INFO : train_sample_misclass     0.18323\n",
      "2017-07-05 21:24:58,339 INFO : valid_sample_misclass     0.19430\n",
      "2017-07-05 21:24:58,340 INFO : test_sample_misclass      0.26149\n",
      "2017-07-05 21:24:58,340 INFO : train_misclass            0.10702\n",
      "2017-07-05 21:24:58,341 INFO : valid_misclass            0.12291\n",
      "2017-07-05 21:24:58,342 INFO : test_misclass             0.16875\n",
      "2017-07-05 21:24:58,342 INFO : runtime                   1.85871\n",
      "2017-07-05 21:24:58,343 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We arrive at ca. 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you want to do trialwise decoding instead of cropped decoding, perform the following changes:\n",
    "\n",
    "\n",
    "Change:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "```\n",
    "\n",
    "to:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = train_set.X.shape[2]\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "```python\n",
    "to_dense_prediction_model(model)\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "\n",
    "```python\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "iterator = BalancedBatchSizeIterator(batch_size=32)\n",
    "```\n",
    "\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "loss_function = F.nll_loss\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='misclass'), \n",
    "            RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "Resulting code can be seen at [BBCI Data Epoched](BBCI_Data_Epoched.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
